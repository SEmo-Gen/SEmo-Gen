<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SEmo-Gen</title>

  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">

        <h1 class="title is-1 publication-title">
          <span style="color: #A063D3;">S</span><span style="color: #EE912A;">Emo</span>-Gen: Unified <span style="color: #EE912A;">Semantics-guided</span> and <span style="color: #A063D3;">Emotion-aware</span> Generation of 3D Human Motion, Expression and Audio
        </h1>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser_v2.png" alt="Teaser figure" style="width: 100%;">
      <h2 class="subtitle has-text-centered">
        SEmo-Gen generates emotion-guided and semantically aligned 3D motion, expression, and audio driven by real-world scenarios.
      </h2>
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-combined">
          <video poster="" id="combined" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_combined/1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-t2m">
          <video poster="" id="t2m" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_t2m/1.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-bottom: 2rem;">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In the real world, human behaviors are not merely mechanical executions (e.g., lifting the right hand) but complex reactions driven by scenario semantics and emotional states (e.g., stepping back and covering the mouth in disbelief upon hearing shocking news). However, existing motion generation methods primarily focus on explicit action verbs, often neglecting the rich scenario-based semantics and emotional states that dictate movement style and dynamics. 
            Moreover, neglecting the intrinsic synergy among the deeply interconnected modalities of motion, expression, and audio under shared semantic and affective contexts results in fragmented behaviors lacking coherence and authenticity.
            In this paper, we propose SEmo-Gen, a unified framework for synchronized 3D motion, expression, and audio generation that enables fine-grained emotional differentiation across diverse scenario semantics.
            To address semantic–emotion conflicts, SEmo-Gen introduces the decoupled semantic-emotion schemes and the custom kinematic loss that enhances emotion-aware physical expressiveness.
            Furthermore, we present SEmo-X, the first multimodal dataset that provides strictly aligned motion, bilingual audio, utterances, emotions, and scenario semantics, along with an emotion-controllable, scenario-guided human motion generation benchmark SEmo-bench on the SMPL-X format.
            Extensive experiments confirm that SEmo-Gen significantly outperforms baselines in emotion expressivity and semantic alignment, marking a shift from instruction-following to scenario-comprehending and emotion-driven digital human synthesis.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <video id="paper-video" controls playsinline width="100%">
            <source src="xxx"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Dataset. -->
    <div class="columns is-centered" style="margin-bottom: 3rem;">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-bottom: 2rem;">Dataset</h2>
        <img src="./static/images/dataset_demo.png" alt="Dataset demo" style="width: 100%;">
        <p class="has-text-justified" style="margin-top: 1.5rem;">
          <b>Dataset Demo.</b> We introduce the SEmo-X dataset, which is the first 3D motion dataset that aligns five elements: motion, bilingual audio, utterances, scenario text, and emotion labels. The entire dataset is based on 63 common real-world scenes, where five subjects perform emotionally
          and motionally appropriate actions based on specific scene utterances and record emotion-rich audio.
          <!-- More visualisations of motion–utterance pairs from the dataset. (a) A rain-shielding scenario on a rainy day; (b) writing problem-solving steps on the blackboard in a teaching scenario; (c) fanning in a hot environment; (d) stepping forward to embrace a long-unseen friend. -->
        </p>
      </div>
    </div>
    
    <!--/ Dataset. -->

    <!-- Method Overview. -->
    <div class="columns is-centered" style="margin-bottom: 3rem;">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-bottom: 2rem;">Method</h2>
        <img src="./static/images/pipeline.png" alt="Overview" style="width: 100%;">
        <p class="has-text-justified" style="margin-top: 1.5rem;">
          <b>Method Overview.</b> Overview. Taking scenario semantics and emotion labels as inputs, SEmo-Gen employs a dual-branch architecture to generate aligned holistic poses, expressions, and audio. The Audio branch synthesizes emotion-aware mel-spectrograms and audio to establish a cross-modal foundation. Simultaneously, the Motion branch integrates $f_{emo}$ and $f_{sem}$ through an expression generator and SEmo-DiT, yielding synchronized expressions and holistic poses.
        </p>
      </div>
    </div>
  </div>
    <!--/ Method Overview. -->

    <!-- Results. -->
    <div class="columns is-centered" style="margin-bottom: 3rem;">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-bottom: 2rem;">Generation</h2>
        
        <div class="columns is-vcentered" style="margin-top: 2rem;">
          <div class="column">
            <div style="display: flex; flex-direction: column; align-items: center;">
              <video autoplay controls muted loop playsinline height="300" style="margin-bottom: 0.5rem;">
                <source src="./static/videos_combined/say_hi_happy.mp4" type="video/mp4">
              </video>
              <p style="margin: 0 1rem; font-size: 1rem; color: #363636; text-align: center; min-height: 3.2em;">
                Say Hi (Happy)
              </p>
            </div>
          </div>
          <div class="column">
            <div style="display: flex; flex-direction: column; align-items: center;">
              <video autoplay controls muted loop playsinline height="300" style="margin-bottom: 0.5rem;">
                <source src="./static/videos_combined/write_on_the_blackboard_neutral.mp4" type="video/mp4">
              </video>
              <p style="margin: 0 1rem; font-size: 1rem; color: #363636; text-align: center; min-height: 3.2em;">
                Write on the Blackboard (Neutral)
              </p>
            </div>
          </div>
        </div>

      </div>
    </div>
    <!--/ Results. -->


    <!-- Contributions. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Contributions</h2>

        <div class="content has-text-justified">
          <ul>
            <li>
            </li>
          </ul>
        </div>
      </div>
    </div> -->
    <!--/ Contributions. -->

  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>

